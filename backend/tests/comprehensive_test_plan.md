# ğŸ§ª GeoLens å¼•ç”¨æ£€æµ‹åŠŸèƒ½å…¨é¢æµ‹è¯•è®¡åˆ’

## ğŸ“Š å½“å‰æµ‹è¯•çŠ¶æ€
- **å•å…ƒæµ‹è¯•**: 20/20 é€šè¿‡ âœ… (100%)
- **APIé›†æˆæµ‹è¯•**: 16/21 é€šè¿‡ âœ… (76%)
- **æ€»ä½“é€šè¿‡ç‡**: 36/41 = 88%

## ğŸ¯ æµ‹è¯•ç›®æ ‡
ç¡®ä¿å¼•ç”¨æ£€æµ‹MVPåŠŸèƒ½100%ç¨³å®šå¯é ï¼Œä¸ºSprint 4åšå¥½å‡†å¤‡ã€‚

---

## Phase 1: ä¿®å¤ç°æœ‰æµ‹è¯•é—®é¢˜ (ä¼˜å…ˆçº§ï¼šé«˜)

### 1.1 ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜
**é—®é¢˜**: datetimeå¯¹è±¡æ— æ³•JSONåºåˆ—åŒ–
**å½±å“**: 5ä¸ªAPIé”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨main.pyä¸­æ·»åŠ è‡ªå®šä¹‰JSONç¼–ç å™¨
from datetime import datetime
import json

class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

# åœ¨FastAPIåº”ç”¨ä¸­ä½¿ç”¨
app = FastAPI(
    title="GeoLens API",
    json_encoder=DateTimeEncoder
)
```

### 1.2 å®Œå–„é”™è¯¯å¤„ç†æµ‹è¯•
**ç›®æ ‡**: ç¡®ä¿æ‰€æœ‰é”™è¯¯åœºæ™¯éƒ½èƒ½æ­£ç¡®å¤„ç†
**æµ‹è¯•ç”¨ä¾‹**:
- [ ] AIæœåŠ¡è¶…æ—¶å¤„ç†
- [ ] ç½‘ç»œè¿æ¥å¤±è´¥å¤„ç†
- [ ] æ— æ•ˆè¾“å…¥å‚æ•°å¤„ç†
- [ ] è®¤è¯å¤±è´¥å¤„ç†

---

## Phase 2: æ ¸å¿ƒåŠŸèƒ½æ·±åº¦æµ‹è¯• (ä¼˜å…ˆçº§ï¼šé«˜)

### 2.1 å¼•ç”¨æ£€æµ‹ç®—æ³•æµ‹è¯•
**ç›®æ ‡**: éªŒè¯NER+å…³é”®è¯åŒ¹é…ç®—æ³•å‡†ç¡®ç‡â‰¥95%

#### æµ‹è¯•æ•°æ®é›†
```python
test_cases = [
    # ç²¾ç¡®åŒ¹é…
    {
        "text": "æˆ‘æ¨èä½¿ç”¨Notionä½œä¸ºå›¢é˜Ÿåä½œå·¥å…·",
        "brands": ["Notion", "Obsidian"],
        "expected": {"Notion": True, "Obsidian": False}
    },
    # å¤§å°å†™ä¸æ•æ„Ÿ
    {
        "text": "notionæ˜¯ä¸ªä¸é”™çš„é€‰æ‹©",
        "brands": ["Notion"],
        "expected": {"Notion": True}
    },
    # å¤šå“ç‰ŒæåŠ
    {
        "text": "å¯¹æ¯”Notionã€Obsidianå’ŒRoam Research",
        "brands": ["Notion", "Obsidian", "Roam Research"],
        "expected": {"Notion": True, "Obsidian": True, "Roam Research": True}
    },
    # ä¸Šä¸‹æ–‡å¹²æ‰°
    {
        "text": "æˆ‘ä¸æ¨èä½¿ç”¨Notionï¼Œå› ä¸ºæœ‰bug",
        "brands": ["Notion"],
        "expected": {"Notion": True}  # ä»ç„¶è¢«æåŠï¼Œä½†ç½®ä¿¡åº¦åº”è¯¥è¾ƒä½
    }
]
```

#### å‡†ç¡®ç‡æµ‹è¯•
```python
def test_algorithm_accuracy():
    """æµ‹è¯•ç®—æ³•å‡†ç¡®ç‡"""
    correct_predictions = 0
    total_predictions = 0
    
    for case in test_cases:
        result = mention_service._analyze_mentions(
            case["text"], 
            case["brands"]
        )
        
        for mention in result:
            expected = case["expected"][mention.brand]
            actual = mention.mentioned
            
            if expected == actual:
                correct_predictions += 1
            total_predictions += 1
    
    accuracy = correct_predictions / total_predictions
    assert accuracy >= 0.95, f"ç®—æ³•å‡†ç¡®ç‡{accuracy:.2%}ä½äº95%è¦æ±‚"
```

### 2.2 ç½®ä¿¡åº¦è¯„åˆ†æµ‹è¯•
**ç›®æ ‡**: éªŒè¯ç½®ä¿¡åº¦è¯„åˆ†çš„åˆç†æ€§

```python
def test_confidence_scoring():
    """æµ‹è¯•ç½®ä¿¡åº¦è¯„åˆ†"""
    # æ­£é¢ä¸Šä¸‹æ–‡åº”è¯¥æœ‰é«˜ç½®ä¿¡åº¦
    positive_text = "æˆ‘å¼ºçƒˆæ¨èNotionï¼Œå®ƒæ˜¯ä¼˜ç§€çš„å·¥å…·"
    positive_score = service._calculate_confidence(positive_text, "Notion", 6)
    assert positive_score > 0.8
    
    # è´Ÿé¢ä¸Šä¸‹æ–‡åº”è¯¥æœ‰è¾ƒä½ç½®ä¿¡åº¦
    negative_text = "æˆ‘ä¸æ¨èNotionï¼Œå› ä¸ºæœ‰é—®é¢˜"
    negative_score = service._calculate_confidence(negative_text, "Notion", 3)
    assert negative_score < 0.8
    
    # ä¸­æ€§ä¸Šä¸‹æ–‡åº”è¯¥æœ‰ä¸­ç­‰ç½®ä¿¡åº¦
    neutral_text = "Notionæ˜¯ä¸€ä¸ªåä½œå·¥å…·"
    neutral_score = service._calculate_confidence(neutral_text, "Notion", 0)
    assert 0.6 <= neutral_score <= 0.9
```

### 2.3 å¤šæ¨¡å‹å¹¶è¡Œæµ‹è¯•
**ç›®æ ‡**: éªŒè¯å¤šæ¨¡å‹å¹¶è¡Œè°ƒç”¨çš„ç¨³å®šæ€§

```python
@pytest.mark.asyncio
async def test_parallel_model_calls():
    """æµ‹è¯•å¹¶è¡Œæ¨¡å‹è°ƒç”¨"""
    start_time = time.time()
    
    result = await mention_service.check_mentions(
        prompt="æ¨èåä½œå·¥å…·",
        brands=["Notion", "Obsidian"],
        models=["doubao", "deepseek", "chatgpt"],
        project_id="test"
    )
    
    end_time = time.time()
    
    # éªŒè¯ç»“æœ
    assert len(result.results) == 3
    assert result.status == "completed"
    
    # éªŒè¯å¹¶è¡Œæ€§èƒ½ï¼ˆåº”è¯¥æ¯”ä¸²è¡Œå¿«ï¼‰
    assert end_time - start_time < 10  # 10ç§’å†…å®Œæˆ
    
    # éªŒè¯æ¯ä¸ªæ¨¡å‹éƒ½æœ‰ç»“æœ
    models_tested = [r.model for r in result.results]
    assert "doubao" in models_tested
    assert "deepseek" in models_tested
    assert "chatgpt" in models_tested
```

---

## Phase 3: è¾¹ç•Œæ¡ä»¶å’Œå‹åŠ›æµ‹è¯• (ä¼˜å…ˆçº§ï¼šä¸­)

### 3.1 è¾¹ç•Œæ¡ä»¶æµ‹è¯•
```python
def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæ¡ä»¶"""
    # ç©ºè¾“å…¥
    result = service._analyze_mentions("", ["Notion"])
    assert len(result) == 1
    assert not result[0].mentioned
    
    # è¶…é•¿æ–‡æœ¬
    long_text = "Notion " * 1000
    result = service._analyze_mentions(long_text, ["Notion"])
    assert result[0].mentioned
    
    # ç‰¹æ®Šå­—ç¬¦
    special_text = "ä½¿ç”¨Notionï¼@#$%^&*()å·¥å…·"
    result = service._analyze_mentions(special_text, ["Notion"])
    assert result[0].mentioned
    
    # å¤§é‡å“ç‰Œ
    many_brands = [f"Brand{i}" for i in range(100)]
    result = service._analyze_mentions("test", many_brands)
    assert len(result) == 100
```

### 3.2 æ€§èƒ½å‹åŠ›æµ‹è¯•
```python
@pytest.mark.asyncio
async def test_performance_stress():
    """æ€§èƒ½å‹åŠ›æµ‹è¯•"""
    # å¹¶å‘è¯·æ±‚æµ‹è¯•
    tasks = []
    for i in range(50):
        task = mention_service.check_mentions(
            prompt=f"æµ‹è¯•è¯·æ±‚{i}",
            brands=["Notion"],
            models=["doubao"],
            project_id=f"test-{i}"
        )
        tasks.append(task)
    
    start_time = time.time()
    results = await asyncio.gather(*tasks)
    end_time = time.time()
    
    # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
    assert len(results) == 50
    for result in results:
        assert result.status == "completed"
    
    # éªŒè¯æ€§èƒ½ï¼ˆå¹³å‡æ¯ä¸ªè¯·æ±‚<2ç§’ï¼‰
    avg_time = (end_time - start_time) / 50
    assert avg_time < 2.0
```

---

## Phase 4: é›†æˆå’Œç«¯åˆ°ç«¯æµ‹è¯• (ä¼˜å…ˆçº§ï¼šä¸­)

### 4.1 å®Œæ•´APIæµç¨‹æµ‹è¯•
```python
@pytest.mark.asyncio
async def test_complete_api_workflow():
    """æµ‹è¯•å®Œæ•´APIå·¥ä½œæµç¨‹"""
    # 1. å¥åº·æ£€æŸ¥
    health_response = client.get("/api/v1/api/health")
    assert health_response.status_code == 200
    
    # 2. æ‰§è¡Œå¼•ç”¨æ£€æµ‹
    check_response = client.post("/api/v1/api/check-mention", json={
        "project_id": "test-project",
        "prompt": "æ¨èåä½œå·¥å…·",
        "brands": ["Notion", "Obsidian"],
        "models": ["doubao", "deepseek"]
    })
    assert check_response.status_code == 200
    check_data = check_response.json()
    
    # 3. æŸ¥è¯¢å†å²è®°å½•
    history_response = client.get("/api/v1/api/get-history", params={
        "project_id": "test-project"
    })
    assert history_response.status_code == 200
    
    # 4. è·å–ç»Ÿè®¡åˆ†æ
    analytics_response = client.get("/api/v1/api/analytics/mentions", params={
        "project_id": "test-project",
        "brand": "Notion"
    })
    assert analytics_response.status_code == 200
    
    # 5. ç«å“å¯¹æ¯”
    compare_response = client.get("/api/v1/api/analytics/compare", params={
        "project_id": "test-project",
        "brands": "Notion,Obsidian"
    })
    assert compare_response.status_code == 200
```

### 4.2 æ•°æ®ä¸€è‡´æ€§æµ‹è¯•
```python
def test_data_consistency():
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
    # æ‰§è¡Œæ£€æµ‹
    result = mention_service.check_mentions(...)
    
    # éªŒè¯æ•°æ®å­˜å‚¨
    stored_data = mention_service.checks_storage[result.check_id]
    assert stored_data["prompt"] == result.prompt
    assert len(stored_data["results"]) == len(result.results)
    
    # éªŒè¯ç»Ÿè®¡æ•°æ®æ›´æ–°
    analytics = mention_service.get_mention_analytics(...)
    assert analytics["total_checks"] > 0
```

---

## Phase 5: å®‰å…¨å’Œå¯é æ€§æµ‹è¯• (ä¼˜å…ˆçº§ï¼šä½)

### 5.1 å®‰å…¨æµ‹è¯•
```python
def test_security():
    """å®‰å…¨æµ‹è¯•"""
    # SQLæ³¨å…¥æµ‹è¯•
    malicious_input = "'; DROP TABLE users; --"
    response = client.post("/api/v1/api/check-mention", json={
        "project_id": malicious_input,
        "prompt": "test",
        "brands": ["test"],
        "models": ["doubao"]
    })
    # åº”è¯¥è¢«å®‰å…¨å¤„ç†ï¼Œä¸ä¼šå¯¼è‡´ç³»ç»Ÿé”™è¯¯
    
    # XSSæµ‹è¯•
    xss_input = "<script>alert('xss')</script>"
    response = client.post("/api/v1/api/check-mention", json={
        "prompt": xss_input,
        "brands": ["test"],
        "models": ["doubao"]
    })
    # åº”è¯¥è¢«æ­£ç¡®è½¬ä¹‰
```

### 5.2 å®¹é”™æ€§æµ‹è¯•
```python
@pytest.mark.asyncio
async def test_fault_tolerance():
    """å®¹é”™æ€§æµ‹è¯•"""
    # æ¨¡æ‹ŸAIæœåŠ¡ä¸å¯ç”¨
    with patch('app.services.ai.doubao.DoubaoProvider.chat') as mock_chat:
        mock_chat.side_effect = Exception("Service unavailable")
        
        result = await mention_service.check_mentions(
            prompt="test",
            brands=["Notion"],
            models=["doubao"],
            project_id="test"
        )
        
        # åº”è¯¥ä¼˜é›…å¤„ç†é”™è¯¯
        assert result.status == "completed"
        assert "Error" in result.results[0].response_text
```

---

## ğŸ“‹ æµ‹è¯•æ‰§è¡Œè®¡åˆ’

### Week 1: ä¿®å¤å’Œæ ¸å¿ƒæµ‹è¯•
- [ ] ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜
- [ ] å®Œå–„é”™è¯¯å¤„ç†æµ‹è¯•
- [ ] æ·±åº¦æµ‹è¯•å¼•ç”¨æ£€æµ‹ç®—æ³•
- [ ] éªŒè¯ç½®ä¿¡åº¦è¯„åˆ†å‡†ç¡®æ€§

### Week 2: æ€§èƒ½å’Œé›†æˆæµ‹è¯•
- [ ] å¤šæ¨¡å‹å¹¶è¡Œæµ‹è¯•
- [ ] è¾¹ç•Œæ¡ä»¶æµ‹è¯•
- [ ] æ€§èƒ½å‹åŠ›æµ‹è¯•
- [ ] å®Œæ•´APIæµç¨‹æµ‹è¯•

### Week 3: å®‰å…¨å’Œå¯é æ€§
- [ ] å®‰å…¨æµ‹è¯•
- [ ] å®¹é”™æ€§æµ‹è¯•
- [ ] æ•°æ®ä¸€è‡´æ€§éªŒè¯
- [ ] æœ€ç»ˆéªŒæ”¶æµ‹è¯•

## ğŸ¯ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•100%é€šè¿‡
- [ ] æ‰€æœ‰é›†æˆæµ‹è¯•100%é€šè¿‡
- [ ] å¼•ç”¨æ£€æµ‹ç®—æ³•å‡†ç¡®ç‡â‰¥95%
- [ ] APIå“åº”æ—¶é—´<2ç§’(95%è¯·æ±‚)

### è´¨é‡éªŒæ”¶
- [ ] ä»£ç è¦†ç›–ç‡â‰¥90%
- [ ] æ— ä¸¥é‡å®‰å…¨æ¼æ´
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æ–‡æ¡£å®Œæ•´å‡†ç¡®

### æ€§èƒ½éªŒæ”¶
- [ ] æ”¯æŒ50+å¹¶å‘è¯·æ±‚
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®š
- [ ] æ— å†…å­˜æ³„æ¼
- [ ] ä¼˜é›…é™çº§å¤„ç†
