#!/usr/bin/env python3
"""
Sprint 3 åŠŸèƒ½æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºå†…å®¹åˆ†æå¼•æ“çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ç½‘é¡µçˆ¬è™«
2. å†…å®¹åˆ†æ
3. GEOè¯„åˆ†
4. å®ä½“æå–
5. å…³é”®è¯åˆ†æ
"""

import asyncio
import json
from datetime import datetime

# å¯¼å…¥æˆ‘ä»¬çš„åˆ†ææ¨¡å—
from app.services.content_processing import ContentExtractor
from app.services.analysis import ContentAnalyzer, KeywordAnalyzer, GEOScorer, EntityExtractor


async def demo_content_processing():
    """æ¼”ç¤ºå†…å®¹å¤„ç†åŠŸèƒ½"""
    print("ğŸ“ æ¼”ç¤ºå†…å®¹å¤„ç†åŠŸèƒ½")
    print("=" * 50)

    # åˆå§‹åŒ–å†…å®¹å¤„ç†å™¨
    content_extractor = ContentExtractor()
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼ˆä¸“æ³¨GEOåˆ†æï¼‰
    sample_content = """
    <html>
        <head>
            <title>æ•°å­—è¥é”€ç­–ç•¥æŒ‡å— - æå‡SEOæ•ˆæœçš„å®Œæ•´æ•™ç¨‹</title>
            <meta name="description" content="å­¦ä¹ æœ€æ–°çš„æ•°å­—è¥é”€ç­–ç•¥ï¼ŒåŒ…æ‹¬SEOä¼˜åŒ–ã€å†…å®¹è¥é”€å’Œç¤¾äº¤åª’ä½“æ¨å¹¿çš„å®ç”¨æŠ€å·§ã€‚">
            <meta name="keywords" content="æ•°å­—è¥é”€,SEO,å†…å®¹è¥é”€,ç¤¾äº¤åª’ä½“">
        </head>
        <body>
            <h1>æ•°å­—è¥é”€ç­–ç•¥æŒ‡å—</h1>
            <h2>SEOä¼˜åŒ–åŸºç¡€</h2>
            <p>æœç´¢å¼•æ“ä¼˜åŒ–(SEO)æ˜¯æ•°å­—è¥é”€çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚é€šè¿‡ä¼˜åŒ–ç½‘ç«™å†…å®¹å’Œç»“æ„ï¼Œå¯ä»¥æ˜¾è‘—æå‡æœç´¢å¼•æ“æ’åã€‚</p>
            <h2>å†…å®¹è¥é”€ç­–ç•¥</h2>
            <p>é«˜è´¨é‡çš„å†…å®¹æ˜¯å¸å¼•ç”¨æˆ·å’Œæœç´¢å¼•æ“çš„å…³é”®ã€‚å†…å®¹è¥é”€éœ€è¦æŒç»­åˆ›ä½œæœ‰ä»·å€¼çš„å†…å®¹ã€‚</p>
            <h3>å…³é”®è¯ç ”ç©¶</h3>
            <p>å…³é”®è¯ç ”ç©¶æ˜¯SEOçš„åŸºç¡€ã€‚é€‰æ‹©æ­£ç¡®çš„å…³é”®è¯å¯ä»¥å¸®åŠ©ç½‘ç«™è·å¾—æ›´å¤šæœ‰é’ˆå¯¹æ€§çš„æµé‡ã€‚</p>
            <h3>æŠ€æœ¯SEO</h3>
            <p>æŠ€æœ¯SEOåŒ…æ‹¬ç½‘ç«™é€Ÿåº¦ä¼˜åŒ–ã€ç§»åŠ¨ç«¯é€‚é…ã€ç»“æ„åŒ–æ•°æ®ç­‰æŠ€æœ¯å±‚é¢çš„ä¼˜åŒ–ã€‚</p>
            <a href="https://example.com/seo-guide">SEOå®Œæ•´æŒ‡å—</a>
            <a href="/internal-link">å†…éƒ¨é“¾æ¥</a>
            <img src="seo-chart.jpg" alt="SEOæ•ˆæœå›¾è¡¨">
            <img src="marketing-funnel.png" alt="">
        </body>
    </html>
    """
    
    # å¤„ç†å†…å®¹
    extracted_content = content_extractor.extract(sample_content, "https://example.com")
    
    print(f"ğŸ“„ æ ‡é¢˜: {extracted_content.title}")
    print(f"ğŸ“ Metaæè¿°: {extracted_content.meta_description}")
    print(f"ğŸ·ï¸  Metaå…³é”®è¯: {extracted_content.meta_keywords}")
    print(f"ğŸ“Š å•è¯æ•°: {extracted_content.word_count}")
    print(f"â±ï¸  é˜…è¯»æ—¶é—´: {extracted_content.reading_time}åˆ†é’Ÿ")
    print(f"ğŸ”— é“¾æ¥æ•°: {len(extracted_content.links)}")
    print(f"ğŸ–¼ï¸  å›¾ç‰‡æ•°: {len(extracted_content.images)}")
    print(f"ğŸ“‹ æ ‡é¢˜ç»“æ„: {extracted_content.headings}")
    print()
    
    return extracted_content


def demo_content_analysis(extracted_content):
    """æ¼”ç¤ºå†…å®¹åˆ†æåŠŸèƒ½"""
    print("ğŸ“Š æ¼”ç¤ºå†…å®¹åˆ†æåŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    content_analyzer = ContentAnalyzer()
    
    # ç›®æ ‡å…³é”®è¯
    target_keywords = ["æ•°å­—è¥é”€", "SEO", "å†…å®¹è¥é”€"]
    
    # æ‰§è¡Œåˆ†æ
    analysis_result = content_analyzer.analyze(extracted_content, target_keywords)
    
    print("ğŸ” SEOåˆ†æç»“æœ:")
    seo = analysis_result.seo_analysis
    print(f"  - æ ‡é¢˜é•¿åº¦: {seo.title_length} å­—ç¬¦ (è¯„åˆ†: {seo.title_score:.2f})")
    print(f"  - Metaæè¿°é•¿åº¦: {seo.meta_description_length} å­—ç¬¦ (è¯„åˆ†: {seo.meta_description_score:.2f})")
    print(f"  - æ ‡é¢˜ç»“æ„è¯„åˆ†: {seo.heading_structure_score:.2f}")
    print(f"  - å†…éƒ¨é“¾æ¥: {seo.internal_links_count} ä¸ª")
    print(f"  - å¤–éƒ¨é“¾æ¥: {seo.external_links_count} ä¸ª")
    print(f"  - ç¼ºå°‘Altæ–‡æœ¬çš„å›¾ç‰‡: {seo.images_without_alt} ä¸ª")
    print(f"  - Schema.orgå­˜åœ¨: {seo.schema_org_present}")
    print(f"  - å…³é”®è¯å¯†åº¦: {seo.keyword_density}")
    print(f"  - SEOæ€»è¯„åˆ†: {seo.overall_score():.2f}")
    print()
    
    print("ğŸ“– å¯è¯»æ€§åˆ†æç»“æœ:")
    readability = analysis_result.readability_analysis
    print(f"  - å•è¯æ•°: {readability.word_count}")
    print(f"  - å¥å­æ•°: {readability.sentence_count}")
    print(f"  - æ®µè½æ•°: {readability.paragraph_count}")
    print(f"  - å¹³å‡å¥é•¿: {readability.avg_words_per_sentence:.1f} è¯/å¥")
    print(f"  - Fleschå¯è¯»æ€§: {readability.flesch_reading_ease:.1f}")
    print(f"  - é˜…è¯»éš¾åº¦: {readability.get_reading_level()}")
    print(f"  - å¯è¯»æ€§è¯„åˆ†: {readability.readability_score:.2f}")
    print()
    
    print("ğŸ—ï¸  ç»“æ„åˆ†æç»“æœ:")
    structure = analysis_result.structure_analysis
    print(f"  - æ ‡é¢˜å±‚çº§: {structure.heading_hierarchy}")
    print(f"  - ç»“æ„é—®é¢˜: {structure.heading_structure_issues}")
    print(f"  - å†…å®¹æ®µè½: {structure.content_sections}")
    print(f"  - ç»“æ„è¯„åˆ†: {structure.structure_score:.2f}")
    print()
    
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    for i, recommendation in enumerate(analysis_result.recommendations, 1):
        print(f"  {i}. {recommendation}")
    print()
    
    print(f"ğŸ¯ æ€»ä½“è¯„åˆ†: {analysis_result.overall_score():.2f}")
    print()
    
    return analysis_result


def demo_keyword_analysis(extracted_content):
    """æ¼”ç¤ºå…³é”®è¯åˆ†æåŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºå…³é”®è¯åˆ†æåŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–å…³é”®è¯åˆ†æå™¨
    keyword_analyzer = KeywordAnalyzer()
    
    # ç›®æ ‡å…³é”®è¯
    target_keywords = ["æ•°å­—è¥é”€", "SEO", "å†…å®¹è¥é”€"]
    
    # æ‰§è¡Œå…³é”®è¯åˆ†æ
    keyword_analysis = keyword_analyzer.analyze(
        content=extracted_content.main_content,
        title=extracted_content.title,
        meta_description=extracted_content.meta_description,
        headings=extracted_content.headings,
        target_keywords=target_keywords
    )
    
    print("ğŸ¯ ç›®æ ‡å…³é”®è¯åˆ†æ:")
    for keyword in keyword_analysis.target_keywords:
        print(f"  - '{keyword.keyword}':")
        print(f"    é¢‘ç‡: {keyword.frequency} æ¬¡")
        print(f"    å¯†åº¦: {keyword.density:.2f}%")
        print(f"    çªå‡ºåº¦: {keyword.prominence_score:.1f}")
        print(f"    ç›¸å…³æ€§: {keyword.context_relevance:.2f}")
    print()
    
    print("ğŸ” å‘ç°çš„å…³é”®è¯:")
    for keyword in keyword_analysis.discovered_keywords[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"  - '{keyword.keyword}': {keyword.frequency} æ¬¡ (å¯†åº¦: {keyword.density:.2f}%)")
    print()
    
    print(f"âš ï¸  å…³é”®è¯å †ç Œé£é™©: {keyword_analysis.keyword_stuffing_risk:.2f}")
    print(f"ğŸ¯ å…³é”®è¯æ€»è¯„åˆ†: {keyword_analysis.overall_keyword_score:.2f}")
    print()
    
    return keyword_analysis


def demo_entity_extraction(extracted_content):
    """æ¼”ç¤ºå®ä½“æå–åŠŸèƒ½"""
    print("ğŸ·ï¸  æ¼”ç¤ºå®ä½“æå–åŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–å®ä½“æå–å™¨
    entity_extractor = EntityExtractor()
    
    # ç›®æ ‡å“ç‰Œ
    target_brands = ["Google", "Facebook", "Microsoft"]
    
    # æ‰§è¡Œå®ä½“æå–
    entity_result = entity_extractor.extract(
        extracted_content.main_content,
        target_brands
    )
    
    print(f"ğŸ‘¥ äººå: {len(entity_result.persons)} ä¸ª")
    for person in entity_result.persons:
        print(f"  - {person.text} (ç½®ä¿¡åº¦: {person.confidence:.2f})")
    
    print(f"ğŸ¢ ç»„ç»‡: {len(entity_result.organizations)} ä¸ª")
    for org in entity_result.organizations:
        print(f"  - {org.text} (ç½®ä¿¡åº¦: {org.confidence:.2f})")
    
    print(f"ğŸ·ï¸  å“ç‰Œ: {len(entity_result.brands)} ä¸ª")
    for brand in entity_result.brands:
        print(f"  - {brand.text} (ç½®ä¿¡åº¦: {brand.confidence:.2f})")
    
    print(f"ğŸ’» æŠ€æœ¯: {len(entity_result.technologies)} ä¸ª")
    for tech in entity_result.technologies:
        print(f"  - {tech.text} (ç½®ä¿¡åº¦: {tech.confidence:.2f})")
    
    print(f"ğŸ“Š å®ä½“æ€»æ•°: {entity_result.get_entity_count()}")
    print()
    
    return entity_result


def demo_geo_scoring(analysis_result, keyword_analysis):
    """æ¼”ç¤ºGEOè¯„åˆ†åŠŸèƒ½"""
    print("ğŸ¯ æ¼”ç¤ºGEOè¯„åˆ†åŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–GEOè¯„åˆ†å™¨
    geo_scorer = GEOScorer()
    
    # è®¡ç®—GEOè¯„åˆ†
    geo_score = geo_scorer.calculate_score(
        content_analysis=analysis_result,
        keyword_analysis=keyword_analysis,
        url="https://example.com/digital-marketing-guide"
    )
    
    print(f"ğŸ† æ€»ä½“è¯„åˆ†: {geo_score.overall_score:.1f}/100")
    print(f"ğŸ“Š è¯„åˆ†ç­‰çº§: {geo_score.get_grade()}")
    print(f"ğŸ‘ï¸  å¯è§æ€§é¢„æµ‹: {geo_score.get_visibility_estimate()}")
    print()
    
    print("ğŸ“ˆ åˆ†ç±»è¯„åˆ†:")
    for category, score in geo_score.category_scores.items():
        print(f"  - {category}: {score:.1f}/100")
    print()
    
    print("ğŸ”§ è¯„åˆ†å› å­:")
    factors = geo_score.factors
    print(f"  - å†…å®¹è´¨é‡: {factors.content_quality:.2f}")
    print(f"  - å†…å®¹é•¿åº¦: {factors.content_length:.2f}")
    print(f"  - å¯è¯»æ€§: {factors.readability:.2f}")
    print(f"  - æ ‡é¢˜ä¼˜åŒ–: {factors.title_optimization:.2f}")
    print(f"  - Metaæè¿°: {factors.meta_description:.2f}")
    print(f"  - æ ‡é¢˜ç»“æ„: {factors.heading_structure:.2f}")
    print(f"  - å†…éƒ¨é“¾æ¥: {factors.internal_linking:.2f}")
    print(f"  - ç»“æ„åŒ–æ•°æ®: {factors.schema_markup:.2f}")
    print(f"  - å…³é”®è¯ç›¸å…³æ€§: {factors.keyword_relevance:.2f}")
    print(f"  - å…³é”®è¯å¯†åº¦: {factors.keyword_density:.2f}")
    print()
    
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    for i, recommendation in enumerate(geo_score.recommendations, 1):
        print(f"  {i}. {recommendation}")
    print()
    
    return geo_score


# ç§»é™¤åçˆ¬è™«æ¼”ç¤ºåŠŸèƒ½ï¼Œä¸“æ³¨GEOåˆ†æ


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ GeoLens Sprint 3 - å†…å®¹åˆ†æå¼•æ“æ¼”ç¤º")
    print("=" * 60)
    print(f"â° æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    try:
        # 1. æ¼”ç¤ºå†…å®¹å¤„ç†
        extracted_content = await demo_content_processing()
        
        # 2. æ¼”ç¤ºå†…å®¹åˆ†æ
        analysis_result = demo_content_analysis(extracted_content)
        
        # 3. æ¼”ç¤ºå…³é”®è¯åˆ†æ
        keyword_analysis = demo_keyword_analysis(extracted_content)
        
        # 4. æ¼”ç¤ºå®ä½“æå–
        entity_result = demo_entity_extraction(extracted_content)
        
        # 5. æ¼”ç¤ºGEOè¯„åˆ†
        geo_score = demo_geo_scoring(analysis_result, keyword_analysis)
        
        # ä¸“æ³¨GEOåˆ†æï¼Œç§»é™¤åçˆ¬è™«æ¼”ç¤º
        
        print("âœ… Sprint 3 åŠŸèƒ½æ¼”ç¤ºå®Œæˆ!")
        print("=" * 60)
        print("ğŸ¯ ä¸»è¦åŠŸèƒ½:")
        print("  âœ… å†…å®¹å¤„ç†ç³»ç»Ÿ")
        print("  âœ… GEOåˆ†æå¼•æ“")
        print("  âœ… å…³é”®è¯ç›¸å…³æ€§åˆ†æ")
        print("  âœ… å®ä½“æå–")
        print("  âœ… GEOè¯„åˆ†ç®—æ³•")
        print("  âœ… AIå‹å¥½åº¦è¯„ä¼°")
        print()
        print("ğŸ“Š åˆ†æç»“æœæ‘˜è¦:")
        print(f"  - GEOè¯„åˆ†: {geo_score.overall_score:.1f}/100 ({geo_score.get_grade()})")
        print(f"  - å†…å®¹è´¨é‡: {analysis_result.content_quality_score:.2f}")
        print(f"  - SEOè¯„åˆ†: {analysis_result.seo_analysis.overall_score():.2f}")
        print(f"  - å…³é”®è¯è¯„åˆ†: {keyword_analysis.overall_keyword_score:.2f}")
        print(f"  - å®ä½“æ•°é‡: {entity_result.get_entity_count()}")
        print()
        print("ğŸ”® ä¸‹ä¸€æ­¥: Sprint 4 å°†ä¸“æ³¨äºæ•°æ®æŒä¹…åŒ–å’Œé«˜çº§åˆ†æåŠŸèƒ½")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
